\documentclass{article}
\usepackage{cite}
\usepackage[utf8]{inputenc}

\title{Report for Comp Exam}
\author{Siyuan Zhao}
\date{March 2017}

\usepackage{amsmath, mathtools}
\usepackage{amsfonts}
\begin{document}

\maketitle

\section{Random Causal Forest}
\cite{wager2015estimation} proposed random causal forest (RCF) to
infer treatment effect. From the conceptual point of view, trees and forests can be viewed as
nearest neighbor methods with an adaptive neighborhood metric. Given
observed independent samples $(X_i, Y_i, W_i)$, a causal tree is first
built by recursively splitting the feature space until all samples are
partitioned into a set of leaves $L$, each of which contains a few
training samples. Then, for a data point $x$, the predicted outcome $\hat{\mu}(x)$
is evaluated by identifying the leaf $L(x)$ containing $x$ and
calculating

$$\hat{\mu} = \frac{1}{\left | \left \{ i: X_i \in L(x) \right \}
  \right |} \sum_{\left \{ i: X_i \in L(x) \right \}} Y_i$$

Given a test point $x$, the closest points to $x$ are those fall in the same
leaf as it. The authors believe that the leaf is small enough that the
responses $Y_i$ are roughly identically distributed. Then the
treatment effect $\hat{\tau}$ for any $x \in L(x)$ is estimated as
following:

\begin{align*}
\hat{\tau}(x) & = \frac{1}{\left | \left \{ i: W_i=1, X_i \in L(x) \right \}
  \right |} \sum_{\left \{ i: W_i = 1, X_i \in L(x) \right \}} Y_i \\ & - \frac{1}{\left | \left \{ i: W_i=0, X_i \in L(x) \right \}
  \right |} \sum_{\left \{ i: W_i = 0, X_i \in L(x) \right \}} Y_i
\end{align*}
RCF assumes that
there is overlapping in the data, i.e., for some $\epsilon > 0$ and
all $x \in \left [ 0, 1\right ]^d$,

$$\epsilon < \mathbb{P}\left [ W=1 \mid X=x \right ] < 1-\epsilon$$

This condition effectively guarantees that, for large enough $n$,
there will be enough treatment and control units near any test point
$x$ for local methods to work.

\section{Bayesian Optimization}
Bayesian optimization is a sequential design strategy for global optimization of black-box functions that does not require derivatives. Since the objective function is unknown, the Bayesian
strategy is to treat it as a random function and place a prior over it. The prior captures our beliefs about the behaviour of the
function. After gathering the function evaluations, which are treated
as data, the prior is updated to form the posterior distribution
over the objective function. The posterior distribution, in turn, is
used to construct an acquisition function that determines what the
next query point should be. Examples of acquisition functions includes
probability of improvement, expected improvement, Bayesian expected
losses, upper confidence bounds (UCB), Thompson sampling and mixtures
of these. They all trade-off exploration and exploitation so as to
minimize the number of function queries. As such, Bayesian
optimization is well suited for functions that are very expensive to evaluate.

In summary, Bayesian optimization is the combination of two main components: a surrogate model which captures all prior and observed information and a decision process which performs the optimal action, i.e.: where to sample next, based on the previous model.

However, the Gaussian process (GP) is the most popular model due to
its accuracy, robustness and flexibility, because Bayesian
optimization is mainly usesd in blck-box scenarios. The range of
applicaility of a Gaussian process is defined by its kernel function,
which sets the family of functions that is able to represent through
the reproducing kernel Hilbert space (RKHS). In BO, attributes of the
GP such as mean and variance are used to sample successive points. It
is suitable for situations where cost function is costly to evaluate
and MCMC techniques would not work.

\section{Propensity Score Matching}
A propensity score is the probability of a unit (e.g., student,
classroom, school) being assigned to a particular treatment given a
set of observed covariates. Propensity scores are used to reduce
selection bias by equating groups based on these covariates.

Propensity score matching (PSM) entails forming matched sets of treated and
untreated subjects who share a similar value of the propensity
score. PSM allows one to estimate the average treatment effect for the
treated (ATT). The ATT is the average effect of treatment on those
subjects who ultimately receive the treatment. The most common
implementation of PSM is one-to-one or pair matching, in which pairs
of treated and untreated subjects are formed, such that matched
subjects have similar values of the propensity score. Once a matched
sample has been formed, the treatment effect can be estimated by
directly comparing outcomes between treated and untreated subjects in
the matched sample. If the outcome is continuous, the effect of
treatment can be estimated as the difference between the mean outcome
for treated subjects and the mean outcome for untreated subjects in
the matched sample. If the outcome is binary, the effect of treatment
can be estimated as the difference between the proportion of subjects
experiencing the event in each of the two groups (treated
vs. untreated) in the matched sample.

Suppose that we have a binary treatment $T={0,1}$, an outcome $Y$, and
background variables $X$. The propensity score is defined as the
conditional probability of treatment given background variables:

$$p(x):= \Pr(T=1 \mid X=x)$$

Let $Y(0)$ and $Y(1)$ denote the potential outcomes under the control
and the treatment, respectively.

The possibility of bias arises because the apparent difference in outcome between these two groups of units may depend on characteristics that affected whether or not a unit received a given treatment instead of due to the effect of the treatment per se. In randomized experiments, the randomization enables unbiased estimation of treatment effects; for each covariate, randomization implies that treatment-groups will be balanced on average, by the law of large numbers. Unfortunately, for observational studies, the assignment of treatments to research subjects is typically not random. Matching attempts to mimic randomization by creating a sample of units that received the treatment that is comparable on all observed covariates to a sample of units that did not receive the treatment.


\section{Gaussian Processes}
Bayesian algorithms do not attempt to identify ‘best-fit’ models of the data (or similarly, make 'best guess' predictions for new test inputs). Instead, they compute a posterior distribution over models (or similarly, compute posterior predictive distributions for new test input). These distributions provide a useful way to quantify our uncertainty in model estimates, and to exploit our knowledge of this uncertainty in order to make more robust predictions on new test points.

Gaussian processes is the extension of multivariate Gaussian to infinite-sized collections of real-valued variables. In particular, this extension will allow us to think of Gaussian processes as distributions not just over random vectors but in fact distributions over random functions.

\subsection{Probability distributions over functions with finite domains}
Let $\mathcal{X} = \left \{ x_1, x_2, …, x_m \right \}$ be any finite set of elements. Consider the set $\mathcal{H}$ of all possible functions mapping from $\mathcal{X}$ to $\mathbf{R}$. For instance, one example of a function $f_0(\cdot) \in \mathcal{H}$ is given by

$$f_0(x_1)=5,~f_0(x_2)=2.3, \dotsb ,~f_0(x_{m-1})=-\pi,~f_0(x_m)=8.$$

Since the domain of any $f(\cdot) \in \mathcal{H}$ has only $m$ elements, we can always represent $f(\cdot)$ compactly as an $m$-dimensional vector, $\vec{f}=[f(x_1)~~f(x_2)~~...~~f(x_m) ]^T$. In order to specify a probability distribution over functions $f(\cdot) \in \mathcal{H}$, we must associate some "probability density" with each function in $\mathcal{H}$. One natural way to do this is to exploit the one-to-one correspondence between $f(\cdot) \in \mathcal{H}$ and their vector representation, $\vec{f}$. In particular, if we specify that $\vec{f}\sim \mathcal{N}(\vec{\mu},\sigma ^2I)$, then this in turn implies a probability distribution over functions $f(\cdot)$, whose probability density function is given by
$$p(h) = \prod_{i=1}^{m} \frac{1}{\sqrt{2\pi}\sigma}\mathrm{exp}(-\frac{1}{2\sigma ^2} (f(x_i)-\mu _i)^2)
$$

In the example above, we show that probability distributions over functions with finite domains can be represented using a finite-dimensional multivariate Gaussian distribution over function outputs $f(x_1),...,f(x_m)$ at a finite number of input points $x1, ..., x_m$

\subsection{Probability distributions over functions with infinite domains}
A stochastic process is a collection of random variables, $\left \{ f(x): x \in \mathcal{X} \right \}$, indexed by elements from some set $\mathcal{X}$, known as the index set. A Gaussian process is a stochastic process such that any finite sub-collection of random variables has a multivariate Gaussian distribution.

In particular, a collection of random variables $\left \{ f(x): x \in \mathcal{X} \right \}$ is said to be drawn from a Gaussian process with mean function $m(\cdot)$ and covariance function $k(\cdot , \cdot)$ if for any finite set of elements $x_1,...,x_m \in \mathcal{X}$, the associated finite set of random variables $f(x_1),...,f(x_m)$ have distribution,
$$\begin{bmatrix}
f(x_1)\\
\vdots \\
f(x_m) 
\end{bmatrix} \sim \mathcal{N} \left( 
\begin{bmatrix}
m(x_1)\\
\vdots \\
m(x_m) 
\end{bmatrix}, \begin{bmatrix}
k(x_1, x_1) & \cdots & k(x_1, x_m) \\
\vdots & \ddots & \vdots\\
k(x_m, x_1) & \cdots & k(x_m, x_m) \\
\end{bmatrix} 
\right).$$

We denote this using the notation,

$$f(\cdot) \sim \mathcal{GP}(m(\cdot), k(\cdot, \cdot)).$$

In general, any real-valued function $m(\cdot)$ is acceptable, but for $k(\cdot, \cdot)$, it must be the case that for any set of elements $x_1, \dotsc, x_m \in \mathcal{X}$, the resulting matrix
$$K = \begin{bmatrix}
k(x_1, x_1) & \cdots & k(x_1, x_m) \\
\vdots & \ddots & \vdots\\
k(x_m, x_1) & \cdots & k(x_m, x_m) \\
\end{bmatrix} $$
is a valid covariance matrix corresponding to some multivariate
Gaussian distribution. A standard result in probability theory states
that this is true provided that $K$ is positive semi-definite.

\section{Reproducing kernel Hilbert space}
In functional analysis, a reproducing kernel Hilbert space (RKHS) is a
Hilbert space of functions in which point evaluation is a continuous
linear functional. The representer theorem states that every function
in an RKHS that minimizes an empirical risk function can be written as
a linear combination of the kernel function evaluated at the training
points.

\bibliographystyle{plain}
\bibliography{references}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
