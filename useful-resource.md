[A Beginnerâ€™s Tutorial for Restricted Boltzmann Machines](https://deeplearning4j.org/restrictedboltzmannmachine)

> A helpful and gentle tutorial on RBM

[Gaussian processes](http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf)

> Tutorial on Gaussian processes

[A Tutorial on Variational Bayesian Inference](http://www.orchid.ac.uk/eprints/40/1/fox_vbtut.pdf)

[A Tutorial Introduction to Belief Propagation](http://computerrobotvision.org/2009/tutorial_day/crv09_belief_propagation_v2.pdf)

[A Tutorial on Bayesian Optimization for Machine Learning](https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf)

[Reproducing Kernel Hilbert Spaces](http://www.mit.edu/~9.520/scribe-notes/class03_gdurett.pdf)

> Lecture notes from MIT course Statistical Learning Theory and Applications

[Introduction to RKHS, and some simple kernel algorithms](http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf)

> Lecture notes from Arthur Gretton

[Personalized Medicine and Artifical Intelligence](http://www.stat.purdue.edu/symp2012/slides/session_15/Kosorok.pdf)

> Slides from Michael Kosorok. It covers several methods for individual treatment rules (ITR) and gives a good introduction to the problem setup of ITR.

[Gaussian processes](http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf)
> Good intro to Gaussian processes and concrete example of Gaussian processes regression, but it does not talk about Bayesian optimization.

[Course in Bayesian Optimization](http://javiergonzalezh.github.io/archive4_teaching.html)
> Slides, code and videos from a summer course on BO.

[AN INTRODUCTION TO MCMC SAMPLING METHODS](http://www.statistics.com/papers/LESSON1_Notes_MCMC.pdf)

[Information gain](https://courses.cs.washington.edu/courses/cse455/10au/notes/InfoGain.pdf)
> Slides on information gain. It gives an intuitive explanation of entropy and information gain.

[Design Matrix](https://en.wikipedia.org/wiki/Design_matrix)

[KL-divergence as an objective function](http://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/)

[Slides on Learning from the Wisdom of Crowds by Minimax Entropy](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/12/MinimaxEnt.pdf)
> This slides are easier for me to understand the idea in the paper.

[Using Lagrange multipliers in optimization](http://kitchingroup.cheme.cmu.edu/blog/2013/02/03/Using-Lagrange-multipliers-in-optimization/)
> There is a simple way to calculate partial derivative in this post.

[Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)
> A good tutorial on confusion matrix.

[Principle of Maximum Entropy: Simple Form](http://www-mtl.mit.edu/Courses/6.050/2003/notes/chapter9.pdf)
> A lecture note on principle of maximum entropy from an MIT course.

[An Introduction to Factor Graphs](http://people.binf.ku.dk/~thamelry/MLSB08/hal.pdf)
